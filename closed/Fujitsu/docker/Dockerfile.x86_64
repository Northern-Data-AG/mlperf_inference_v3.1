# Copyright (c) 2023, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ARG BASE_IMAGE
FROM ${BASE_IMAGE} as base

ENV http_proxy=http://empllinux:1234567890@rep2-ng.proxy.nic.fujitsu.com:8080
ENV https_proxy=http://empllinux:1234567890@rep2-ng.proxy.nic.fujitsu.com:8080

# Explicitly use bash instead of sh ('echo' behaves differently on some shells)
SHELL ["/bin/bash", "-c"]

ARG CUDA_VER=12.2
ARG USE_CPU=0
ARG USE_NIGHTLY=0
ARG USE_NGC=0
ARG MITTEN_VER

ENV LC_ALL=C.UTF-8
ENV LANG=C.UTF-8

ENV TZ=ETC/UTC
ENV DEBIAN_FRONTEND=noninteractive

# Install core packages
# MLPINF-1247 - Some partners in China are reporting DNS issues with Apt, specifically with cuda-repo. Remove the .list.
RUN rm -f /etc/apt/sources.list.d/cuda.list \
 && apt update \
 && apt install -y --no-install-recommends build-essential autoconf libtool git \
        ccache curl wget pkg-config sudo ca-certificates automake libssl-dev \
        bc python3-dev python3-pip google-perftools gdb libglib2.0-dev clang sshfs libre2-dev \
        libboost-dev libnuma-dev numactl sysstat sshpass ntpdate less vim iputils-ping pybind11-dev \
 && apt install --only-upgrade libksba8 \
 && apt remove -y cmake \
 && apt remove -y libgflags-dev \
 && apt remove -y libprotobuf-dev \
 && apt -y autoremove
RUN apt install -y --no-install-recommends pkg-config zip g++ zlib1g-dev unzip
RUN apt install -y --no-install-recommends libarchive-dev
RUN apt install -y --no-install-recommends rsync


# Install cudnn and TRT if not using NGC base container

# Install cudnn 8.9.2 GA for TRT 9.0.0
ARG CUDNN_DEB_URL=https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/
RUN if [[ ${USE_NGC} = 0 ]]; then \
    cd /tmp \
    && install_deb_pkg() { wget $CUDNN_DEB_URL/$1 -O $1 && dpkg -i $1 && rm $1; } \
    && install_deb_pkg libcudnn8_8.9.2.26-1+cuda12.1_amd64.deb \
    && install_deb_pkg libcudnn8-dev_8.9.2.26-1+cuda12.1_amd64.deb \
    && unset -f install_deb_pkg; fi

# For now, install cudnn 8.8.0 from URM
# ARG CUDNN_URM_URL=https://urm.nvidia.com/artifactory/hw-cudnn-generic/CUDNN/v8.8_cuda_12.0/8.8.0.95/cudnn-linux-x86_64-8.8.0.95.tar.gz
# RUN if [[ ${USE_NGC} = 0 ]]; then \
#   cd /tmp \
#   && rm -rf /usr/lib/x86_64-linux-gnu/libcudnn* \
#   && wget $CUDNN_URM_URL -O cudnn.tar \
#   && tar -xf cudnn.tar \
#   && cp -r cudnn/lib64/* /usr/lib/x86_64-linux-gnu/ \
#   && cp -r cudnn/include/* /usr/include/ \
#   && rm -rf cudnn.tar; fi

# Remove the default TRT installation in the cudnn container if existed
RUN if [[ ${USE_NGC} = 0 ]]; then rm -rf /usr/local/lib/python3.8/dist-packages/tensorrt/; fi

# Install TRT nightly
# (As of 07/25/2023, using TRT rel-9.0-mlpinf cuda-12.2 side branch)
ARG TRT_NIGHTLY_URL=https://urm.nvidia.com/artifactory/sw-tensorrt-generic/cicd/rel-9.0-mlpinf/L1_Custom/2/trt_build_x86_64_linux_agnostic_cuda${CUDA_VER}_full_optimized_agnostic_agnostic.tar
RUN if [[ ${USE_NGC} = 0 ]]; then if [[ $USE_NIGHTLY = 1 ]]; then \
    cd /tmp \
    && wget ${TRT_NIGHTLY_URL} --user tensorrt-read-only --password "Tensorrt@123" -O TRT.tar \
    && tar -xf TRT.tar \
    && cd source/install/x86_64-gnu \
    && mkdir trt \
    && tar -xvzf cuda-${CUDA_VER}/release_tarfile/TensorRT-*.*.x86_64-gnu.cuda-${CUDA_VER}.tar.gz -C trt --strip-components 1 \
    && tar -xvzf TensorRT-*.*.x86_64-gnu.cuda-${CUDA_VER}.internal.tar.gz -C trt --strip-components 1 \
    && cp -rv trt/lib/* /usr/lib/x86_64-linux-gnu/ \
    && cp -rv trt/include/* /usr/include/x86_64-linux-gnu/ \
    && cp -rv trt/bin/* /usr/bin/ \
    && python3 -m pip install trt/onnx_graphsurgeon/*.whl trt/python/tensorrt-*-cp38-none-linux_x86_64.whl \
    && cd ../../.. \
    && rm -rf source \
    && rm -f TRT.tar; fi; fi

# Install TRT RC 9.0.0.3
ARG TRT_DEB_URL=http://cuda-repo/release-candidates/Libraries/TensorRT/v9.0/9.0.0.3-ca26ee05-mlpinf/12.2-r535/Ubuntu20_04-x64-agnostic/deb/
ARG TRT_MAJOR_VER=9
ARG TRT_MINOR_VER=0
ARG TRT_PATCH_VER=0
ARG TRT_QA_VER=3
ARG TRT_VER=${TRT_MAJOR_VER}.${TRT_MINOR_VER}.${TRT_PATCH_VER}.${TRT_QA_VER}
RUN if [[ ${USE_NGC} = 0 ]]; then if [[ $USE_NIGHTLY = 0 ]]; then \
    cd /tmp \
    && install_deb_pkg() { wget -q $TRT_DEB_URL/$1 -O $1 && dpkg -i $1 && rm $1; } \
    && install_deb_pkg libnvinfer${TRT_MAJOR_VER}_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-headers-dev_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-dev_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-headers-plugin-dev_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-lean${TRT_MAJOR_VER}_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-lean-dev_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-dispatch${TRT_MAJOR_VER}_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-dispatch-dev_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-plugin${TRT_MAJOR_VER}_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-plugin-dev_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-vc-plugin${TRT_MAJOR_VER}_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-vc-plugin-dev_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvonnxparsers${TRT_MAJOR_VER}_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvonnxparsers-dev_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg python3-libnvinfer_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg python3-libnvinfer-lean_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg python3-libnvinfer-dispatch_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg python3-libnvinfer-dev_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && install_deb_pkg libnvinfer-bin_${TRT_VER}-1+cuda${CUDA_VER}_amd64.deb \
    && ln -sf /usr/src/tensorrt/bin/trtexec /usr/bin/trtexec \
    && unset -f install_deb_pkg; fi; fi

# With latest Ubuntu:20.04 container, there will be no 'python' or 'pip' even if we have installed 'python3' and
# 'python3-pip'. So add softlink to avoid wheel installation failure.
RUN ln -sf /usr/bin/python3 /usr/bin/python
RUN ln -sf /usr/bin/pip3 /usr/bin/pip

# Install dependencies needed for RNN-T preprocessing
RUN apt install -y sox

# Needed by official RNNT accuracy script
RUN apt install -y --no-install-recommends libsndfile1-dev

# Needed by Triton
RUN apt install -y rapidjson-dev
RUN apt install -y libb64-dev
RUN apt install -y libgtest-dev

# Work around for conditional copy
COPY requirements.x86_64.1.txt requirements.x86_64.2.txt nvmitten-${MITTEN_VER}-cp38-cp38-linux_x86_64.whl* \
    cublas_build_x86_64_centos7_cuda12.2_r535_release.tar.gz* faster-transformer-bert-fp8-weights-scales.tar.gz* /tmp
# NGC Image stores packages in /opt/
RUN if [[ ${USE_NGC} = 1 ]]; then \
    mv /opt/nvmitten-${MITTEN_VER}-cp38-cp38-linux_x86_64.whl /tmp \
    && mv /opt/torch*.whl /opt/pytorch_triton* /tmp \
    && mv /opt/cublas_build_x86_64_centos7_cuda12.2_r535_release.tar.gz /tmp \
    && mv /opt/faster-transformer-bert-fp8-weights-scales.tar.gz /tmp; fi
WORKDIR /tmp

# Set up basic setuptools for pip install commands.
RUN python3 -m pip install --upgrade pip \
 && python3 -m pip install --upgrade setuptools wheel virtualenv

# Break requirements into two lists because some of them require that other packages be fully installed first.
RUN python3 -m pip install -r requirements.x86_64.1.txt \
 && python3 -m pip install -r requirements.x86_64.2.txt

# Uninstall torch-0.14 and install torch-2.1 + torchvision-0.16 from nightly, together with dependencies.
# TODO: Add them to requirements.txt when the public version is out
RUN python3 -m pip uninstall -y torch torchvision \
    && cd /tmp \
    && pip install pytorch*.whl \
    && pip install torch-*.whl torchvision*.whl \
    && rm torch*.whl

# install gflags
# -DBUILD_SHARED_LIBS=ON -DBUILD_STATIC_LIBS=ON -DBUILD_gflags_LIB=ON .. \
RUN git clone -b v2.2.1 https://github.com/gflags/gflags.git \
    && cd gflags \
    && mkdir build && cd build \
    && cmake -DBUILD_SHARED_LIBS=ON -DBUILD_STATIC_LIBS=ON -DBUILD_gflags_LIB=ON .. \
    && make -j \
    && make install \
    && cd /tmp && rm -rf gflags

# install glog
RUN git clone -b v0.3.5 https://github.com/google/glog.git \
    && cd glog \
    && cmake -H. -Bbuild -G "Unix Makefiles" -DBUILD_SHARED_LIBS=ON -DBUILD_STATIC_LIBS=ON \
    && cmake --build build \
    && cmake --build build --target install \
    && cd /tmp && rm -rf glog

# Install CUB, needed by NMS OPT plugin
RUN wget https://github.com/NVlabs/cub/archive/1.8.0.zip -O cub-1.8.0.zip \
    && unzip cub-1.8.0.zip \
    && mv cub-1.8.0/cub /usr/include/x86_64-linux-gnu/ \
    && rm -rf cub-1.8.0.zip cub-1.8.0

# Install libjemalloc2
RUN echo 'deb http://archive.ubuntu.com/ubuntu focal main restricted universe multiverse' | tee -a /etc/apt/sources.list.d/focal.list \
    && echo 'Package: *\nPin: release a=focal\nPin-Priority: -10\n' | tee -a /etc/apt/preferences.d/focal.pref \
    && apt update \
    && apt install --no-install-recommends -t focal -y libjemalloc2 libtcmalloc-minimal4

# Update GLIBC version needed for Triton TF-CPU backend
RUN if [ ${USE_CPU} = 1 ]; then \
    apt update && apt upgrade -y libstdc++6; fi
ENV USE_CPU=${USE_CPU}

# Needed for Mitten
RUN python3 -m pip uninstall -y pic-c

WORKDIR /tmp
RUN python3 -m pip install nvmitten-${MITTEN_VER}-cp38-cp38-linux_x86_64.whl

# GPT core libs
RUN apt install -y openmpi-bin openmpi-common libopenmpi-dev
ARG NCCL_DEB_URL=https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/
RUN cd /tmp \
    && install_deb_pkg() { wget $NCCL_DEB_URL/$1 -O $1 && dpkg -i $1 && rm $1; } \
    && install_deb_pkg cuda-keyring_1.0-1_all.deb \
    && unset -f install_deb_pkg
RUN apt update && apt install -y --allow-change-held-packages libnccl2=2.18.3-1+cuda12.2 libnccl-dev=2.18.3-1+cuda12.2
RUN python3 -m pip install mpi4py==3.1.4

# Unzip cuBLAS nightly build and link to docker CUDA package
WORKDIR /tmp
RUN mkdir cublas_build_x86_64_centos7_cuda12.2_r535_release
RUN tar -zxvf cublas_build_x86_64_centos7_cuda12.2_r535_release.tar.gz -C cublas_build_x86_64_centos7_cuda12.2_r535_release
# Copy all .so files and nothing else
RUN rm /usr/local/cuda/lib64/libcublas* /usr/local/cuda/lib64/libnvblas*
RUN cp cublas_build_x86_64_centos7_cuda12.2_r535_release/cublas-x86_64-centos7-cuda12.2_r535/lib64/*.so* /usr/local/cuda/lib64/

# BERT Fp8 weights
WORKDIR /opt
RUN mkdir -p /opt/fp8/faster-transformer-bert-fp8-weights-scales/ \
    && tar -zxvf /tmp/faster-transformer-bert-fp8-weights-scales.tar.gz -C /opt/fp8/faster-transformer-bert-fp8-weights-scales/ --strip-components=6

# For cv2
RUN apt install -y libgl1-mesa-glx

WORKDIR /work
