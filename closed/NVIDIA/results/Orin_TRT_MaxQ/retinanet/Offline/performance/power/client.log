client 2023-08-10 09:46:22,002 [INFO] Sending command to the server: 'mlcommons/power client v3'
client 2023-08-10 09:46:22,006 [INFO] Got response: 'mlcommons/power server v3'
client 2023-08-10 09:46:22,006 [INFO] Sending command to the server: 'stop'
client 2023-08-10 09:46:22,008 [INFO] Got response: 'OK'
client 2023-08-10 09:46:22,009 [INFO] Synchronizing with the server and with ib-01.dc4-in.nvidia.com...
client 2023-08-10 09:46:22,232 [INFO] NTP:offset = -0.003 s, delay = 0.217 s 
client 2023-08-10 09:46:22,232 [INFO] Sending command to the server: 'time'
client 2023-08-10 09:46:22,236 [INFO] Got response: '1691660782.231149'
client 2023-08-10 09:46:22,236 [INFO] The time difference between the client and the server is within range 1.707 ms..5.665 ms
client 2023-08-10 09:46:22,236 [INFO] Sending command to the server: 'new,,89e1cceb-1499-47d6-855e-996e72b20b3f'
client 2023-08-10 09:46:22,240 [INFO] Got response: 'OK 2023-08-10_02-46-22,89d4b46a-f8fc-4469-bd76-8f25ebcdc0b8'
client 2023-08-10 09:46:22,240 [INFO] Session id is '2023-08-10_02-46-22'
client 2023-08-10 09:46:22,240 [INFO] Sources: {"sources": {"__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "client.py": "33ca4f26368777ac06e01f9567b714a4b8063886", "lib/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "lib/client.py": "ac2aa093c8e8bbc9569b9e2a3471bc64e58a2258", "lib/common.py": "611d8b29633d331eb19c9455ea3b5fa3284ed6df", "lib/external/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "lib/external/ntplib.py": "4da8f970656505a40483206ef2b5d3dd5e81711d", "lib/server.py": "c7af63c31bb2fbedea4345f571f6e3507d268ada", "lib/source_hashes.py": "60a2e02193209e8d392803326208d5466342da18", "lib/summary.py": "aa92f0a3f975eecd44d3c0cd0236342ccc9f941d", "lib/time_sync.py": "122eba67a9abc85635223e054def53be1367ade2", "server.py": "c3f90f2f7eeb4db30727556d0c815ebc89b3d28b", "tests/unit/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "tests/unit/test_server.py": "948c1995d4008bc2aa6c4046a34ffa3858d6d671", "tests/unit/test_source_hashes.py": "00468a2907583c593e6574a1f6b404e4651c221a"}, "modules": {"ptd_client_server.lib.client": "lib/client.py", "ptd_client_server.lib.common": "lib/common.py", "ptd_client_server.lib.external.ntplib": "lib/external/ntplib.py", "ptd_client_server.lib.source_hashes": "lib/source_hashes.py", "ptd_client_server.lib.summary": "lib/summary.py", "ptd_client_server.lib.time_sync": "lib/time_sync.py"}}
client 2023-08-10 09:46:22,241 [INFO] Running workload in ranging mode
client 2023-08-10 09:46:22,241 [INFO] Synchronizing with the server and with ib-01.dc4-in.nvidia.com...
client 2023-08-10 09:46:22,462 [INFO] NTP:offset = -0.003 s, delay = 0.216 s 
client 2023-08-10 09:46:22,463 [INFO] Sending command to the server: 'time'
client 2023-08-10 09:46:22,466 [INFO] Got response: '1691660782.4610238'
client 2023-08-10 09:46:22,466 [INFO] The time difference between the client and the server is within range 2.114 ms..5.276 ms
client 2023-08-10 09:46:22,466 [INFO] Sending command to the server: 'session,2023-08-10_02-46-22,start,ranging'
client 2023-08-10 09:46:50,681 [INFO] Got response: 'OK'
client 2023-08-10 09:46:50,683 [INFO] Sending command to the server: 'time'
client 2023-08-10 09:46:50,689 [INFO] Got response: '1691660810.6831074'
client 2023-08-10 09:46:50,690 [INFO] The time difference between the client and the server is within range -0.112 ms..7.538 ms
client 2023-08-10 09:46:50,692 [INFO] Running the workload 'LOG_DIR=/home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp python3.8 -m code.main --benchmarks=retinanet --scenarios=offline --test_mode=PerformanceOnly --config_ver=maxq --action="run_harness" \\\n\t\t2>&1 | tee -a /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/stdout.txt \\\n\t\t&& if [ ! -d /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/ranging_tmp ]; \\\n\t\t\tthen mkdir /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/ranging_tmp \\\n\t\t\t\t&& mv /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/* /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/ranging_tmp/ \\\n\t\t\t\t&& cp -v /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/ranging_tmp/*/*/*/mlperf_log_detail.txt /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/ \\\n\t\t\t\t&& cp -v /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/ranging_tmp/*/*/*/mlperf_log_summary.txt /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/; \\\n\t\t\telse mkdir /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/testing_tmp \\\n\t\t\t\t&& mv /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/* /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/testing_tmp/ \\\n\t\t\t\t&& cp -v /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/testing_tmp/*/*/*/mlperf_log_detail.txt /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/ \\\n\t\t\t\t&& cp -v /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/testing_tmp/*/*/*/mlperf_log_summary.txt /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/; fi'
client 2023-08-10 09:59:34,999 [INFO] Sending command to the server: 'time'
client 2023-08-10 09:59:35,004 [INFO] Got response: '1691661575.0010488'
client 2023-08-10 09:59:35,005 [INFO] The time difference between the client and the server is within range -1.602 ms..4.080 ms
client 2023-08-10 09:59:35,005 [INFO] Sending command to the server: 'session,2023-08-10_02-46-22,stop,ranging'
client 2023-08-10 09:59:45,748 [INFO] Got response: 'OK'
client 2023-08-10 09:59:45,749 [INFO] Sending command to the server: 'time'
client 2023-08-10 09:59:45,755 [INFO] Got response: '1691661585.751066'
client 2023-08-10 09:59:45,756 [INFO] The time difference between the client and the server is within range -1.720 ms..5.283 ms
client 2023-08-10 09:59:45,813 [INFO] Copying loadgen logs from '/home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp' to '/home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/2023-08-10_02-46-22/ranging'
client 2023-08-10 09:59:45,817 [INFO] Running workload in testing mode
client 2023-08-10 09:59:45,817 [INFO] Synchronizing with the server and with ib-01.dc4-in.nvidia.com...
client 2023-08-10 09:59:46,049 [INFO] NTP:offset = -0.002 s, delay = 0.220 s 
client 2023-08-10 09:59:46,050 [INFO] Sending command to the server: 'time'
client 2023-08-10 09:59:46,058 [INFO] Got response: '1691661586.0528698'
client 2023-08-10 09:59:46,059 [INFO] The time difference between the client and the server is within range -2.127 ms..6.613 ms
client 2023-08-10 09:59:46,060 [INFO] Sending command to the server: 'session,2023-08-10_02-46-22,start,testing'
client 2023-08-10 09:59:59,090 [INFO] Got response: 'OK'
client 2023-08-10 09:59:59,092 [INFO] Sending command to the server: 'time'
client 2023-08-10 09:59:59,096 [INFO] Got response: '1691661599.0936382'
client 2023-08-10 09:59:59,097 [INFO] The time difference between the client and the server is within range -1.612 ms..3.539 ms
client 2023-08-10 09:59:59,098 [INFO] Running the workload 'LOG_DIR=/home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp python3.8 -m code.main --benchmarks=retinanet --scenarios=offline --test_mode=PerformanceOnly --config_ver=maxq --action="run_harness" \\\n\t\t2>&1 | tee -a /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/stdout.txt \\\n\t\t&& if [ ! -d /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/ranging_tmp ]; \\\n\t\t\tthen mkdir /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/ranging_tmp \\\n\t\t\t\t&& mv /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/* /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/ranging_tmp/ \\\n\t\t\t\t&& cp -v /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/ranging_tmp/*/*/*/mlperf_log_detail.txt /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/ \\\n\t\t\t\t&& cp -v /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/ranging_tmp/*/*/*/mlperf_log_summary.txt /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/; \\\n\t\t\telse mkdir /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/testing_tmp \\\n\t\t\t\t&& mv /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/* /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/testing_tmp/ \\\n\t\t\t\t&& cp -v /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/testing_tmp/*/*/*/mlperf_log_detail.txt /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/ \\\n\t\t\t\t&& cp -v /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/testing_tmp/*/*/*/mlperf_log_summary.txt /home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp/; fi'
client 2023-08-10 10:12:54,876 [INFO] Sending command to the server: 'time'
client 2023-08-10 10:12:54,881 [INFO] Got response: '1691662374.880312'
client 2023-08-10 10:12:54,882 [INFO] The time difference between the client and the server is within range -5.014 ms..2.442 ms
client 2023-08-10 10:12:54,883 [INFO] Sending command to the server: 'session,2023-08-10_02-46-22,stop,testing'
client 2023-08-10 10:13:05,142 [INFO] Got response: 'OK'
client 2023-08-10 10:13:05,144 [INFO] Sending command to the server: 'time'
client 2023-08-10 10:13:05,150 [INFO] Got response: '1691662385.1481266'
client 2023-08-10 10:13:05,151 [INFO] The time difference between the client and the server is within range -4.003 ms..3.354 ms
client 2023-08-10 10:13:05,162 [INFO] Copying loadgen logs from '/home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs_temp' to '/home/nvidia/mlperf-inference/closed/NVIDIA/build/power_logs/2023.08.10-09.45.34/2023-08-10_02-46-22/run_1'
client 2023-08-10 10:13:05,170 [INFO] Done runs
