# MLPerf Inference v3.1 Implementations
This is a repository of H3C servers using optimized implementations for [MLPerf Inference Benchmark v3.1](https://www.mlperf.org/inference-overview/).

# Implementations
## Benchmarks
**Please refer to /closed/NVIDIA for detailed instructions for NVIDIA GPU & Triton submissions, including performance guides, and instructions on how to run with new systems.** 

The following benchmarks are part of our submission for MLPerf Inference v3.1:
- [3d-unet](code/3d-unet/tensorrt/README.md)
- [bert](code/bert/tensorrt/README.md)
- [dlrmv2](code/dlrm-v2/tensorrt/README.md)
- [gptj](code/gptj/tensorrt/README.md)
- [rnnt](code/rnnt/tensorrt/README.md)
- [retinanet](code/retinanet/README.md)
- [resnet50](code/resnet50/tensorrt/README.md)

# H3C Submission Systems

The closed systems that H3C has submitted are:
- Datacenter Systems
  - H3C UniServer R5300 G6
    - NVIDIA L40
  - H3C UniServer R5350 G6
    - NVIDIA L40
- Edge Systems
  - H3C UniServer R5300 G6
    - NVIDIA L40
