
# MLPerf Inference v3.1 TTA Submissions

In MLPerf inference v3.1 TTA has submitted results on KR580S1 datacenter in the closed division - using NVidia MLPerf Inference v3.0 code. For ResNet50 TTA has submitted results using Nvidia docker from MLPerf inference v3.0. TTA has also submitted results using the CM API for Nvidia implementation for ResNet50, RetinaNet, Bert, and 3d-unet. 

For reproducing our results using Nvidia docker please follow [this](https://github.com/mlcommons/inference_results_v3.0/blob/main/closed/NVIDIA/README.md) README and use the config files from the [config](./config) folder. For reproducing our results using the CM API, please follow the README files under code/<model> directories.
