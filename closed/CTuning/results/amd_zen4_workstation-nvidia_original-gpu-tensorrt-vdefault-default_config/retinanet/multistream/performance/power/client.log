client 2023-09-02 07:19:27,180 [INFO] Creating output directory '/home/cmuser/CM/repos/mlcommons@ck/cm-mlops/script/run-all-mlperf-models/valid_results/cecdad8c31f6-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream/performance/tmp_power'
client 2023-09-02 07:19:27,463 [INFO] Sending command to the server: 'mlcommons/power client v3'
client 2023-09-02 07:19:27,467 [INFO] Got response: 'mlcommons/power server v3'
client 2023-09-02 07:19:27,467 [INFO] Synchronizing with the server and with time.google.com...
client 2023-09-02 07:19:27,952 [INFO] NTP:offset = 0.000 s, delay = 0.015 s 
client 2023-09-02 07:19:27,952 [INFO] Sending command to the server: 'time'
client 2023-09-02 07:19:27,955 [INFO] Got response: '1693664367.9551394'
client 2023-09-02 07:19:27,955 [INFO] The time difference between the client and the server is within range -2.439 ms..0.024 ms
client 2023-09-02 07:19:27,955 [INFO] Sending command to the server: 'new,,4c7d2de6-b102-4817-bcbf-ceaaffa52ba9'
client 2023-09-02 07:19:27,958 [INFO] Got response: 'OK 2023-09-02_14-19-27,25d9ccf9-745b-4378-b1ba-9ed25e890636'
client 2023-09-02 07:19:27,958 [INFO] Session id is '2023-09-02_14-19-27'
client 2023-09-02 07:19:27,958 [INFO] Sources: {"sources": {"__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "client.py": "33ca4f26368777ac06e01f9567b714a4b8063886", "lib/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "lib/client.py": "ac2aa093c8e8bbc9569b9e2a3471bc64e58a2258", "lib/common.py": "611d8b29633d331eb19c9455ea3b5fa3284ed6df", "lib/external/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "lib/external/ntplib.py": "4da8f970656505a40483206ef2b5d3dd5e81711d", "lib/server.py": "c7af63c31bb2fbedea4345f571f6e3507d268ada", "lib/source_hashes.py": "60a2e02193209e8d392803326208d5466342da18", "lib/summary.py": "aa92f0a3f975eecd44d3c0cd0236342ccc9f941d", "lib/time_sync.py": "80894ef2389e540781ff78de94db16aa4203a14e", "server.py": "c3f90f2f7eeb4db30727556d0c815ebc89b3d28b", "tests/unit/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "tests/unit/test_server.py": "948c1995d4008bc2aa6c4046a34ffa3858d6d671", "tests/unit/test_source_hashes.py": "00468a2907583c593e6574a1f6b404e4651c221a"}, "modules": {"ptd_client_server.lib.client": "lib/client.py", "ptd_client_server.lib.common": "lib/common.py", "ptd_client_server.lib.external.ntplib": "lib/external/ntplib.py", "ptd_client_server.lib.source_hashes": "lib/source_hashes.py", "ptd_client_server.lib.summary": "lib/summary.py", "ptd_client_server.lib.time_sync": "lib/time_sync.py"}}
client 2023-09-02 07:19:27,958 [INFO] Running workload in ranging mode
client 2023-09-02 07:19:27,958 [INFO] Synchronizing with the server and with time.google.com...
client 2023-09-02 07:19:27,987 [INFO] NTP:offset = -0.001 s, delay = 0.014 s 
client 2023-09-02 07:19:27,987 [INFO] Sending command to the server: 'time'
client 2023-09-02 07:19:27,990 [INFO] Got response: '1693664367.989714'
client 2023-09-02 07:19:27,990 [INFO] The time difference between the client and the server is within range -2.565 ms..0.404 ms
client 2023-09-02 07:19:27,990 [INFO] Sending command to the server: 'session,2023-09-02_14-19-27,start,ranging'
client 2023-09-02 07:19:56,073 [INFO] Got response: 'OK'
client 2023-09-02 07:19:56,073 [INFO] Sending command to the server: 'time'
client 2023-09-02 07:19:56,075 [INFO] Got response: '1693664396.0751154'
client 2023-09-02 07:19:56,075 [INFO] The time difference between the client and the server is within range -1.672 ms..0.024 ms
client 2023-09-02 07:19:56,075 [INFO] Running the workload 'CM_MLPERF_RUN_COUNT=$(cat ${CM_RUN_DIR}/count.txt); echo ${CM_MLPERF_RUN_COUNT}; CM_MLPERF_RUN_COUNT=$((CM_MLPERF_RUN_COUNT+1)); echo ${CM_MLPERF_RUN_COUNT} > ${CM_RUN_DIR}/count.txt && if [ ${CM_MLPERF_RUN_COUNT} -eq "1" ]; then export CM_MLPERF_USER_CONF=${CM_MLPERF_RANGING_USER_CONF}; else export CM_MLPERF_USER_CONF=${CM_MLPERF_TESTING_USER_CONF}; fi && make run_harness RUN_ARGS=" --benchmarks=retinanet --scenarios=multistream --test_mode=PerformanceOnly --offline_expected_qps=620 --single_stream_expected_latency_ns=2000000 --multi_stream_expected_latency_ns=14000000 --user_conf_path=${CM_MLPERF_USER_CONF} --mlperf_conf_path=/home/cmuser/CM/repos/local/cache/e08d8d07b7714054/inference/mlperf.conf --gpu_batch_size=2 --no_audit_verify "'
client 2023-09-02 07:25:02,666 [INFO] Sending command to the server: 'time'
client 2023-09-02 07:25:02,734 [INFO] Got response: '1693664702.7341127'
client 2023-09-02 07:25:02,734 [INFO] The time difference between the client and the server is within range -67.489 ms..0.261 ms
client 2023-09-02 07:25:02,734 [INFO] Sending command to the server: 'session,2023-09-02_14-19-27,stop,ranging'
client 2023-09-02 07:25:13,199 [INFO] Got response: 'OK'
client 2023-09-02 07:25:13,199 [INFO] Sending command to the server: 'time'
client 2023-09-02 07:25:13,200 [INFO] Got response: '1693664713.2007873'
client 2023-09-02 07:25:13,200 [INFO] The time difference between the client and the server is within range -1.537 ms..-0.042 ms
client 2023-09-02 07:25:13,202 [INFO] Copying loadgen logs from '/home/cmuser/CM/repos/mlcommons@ck/cm-mlops/script/run-all-mlperf-models/valid_results/cecdad8c31f6-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream/performance/run_1' to '/home/cmuser/CM/repos/mlcommons@ck/cm-mlops/script/run-all-mlperf-models/valid_results/cecdad8c31f6-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream/performance/tmp_power/ranging'
client 2023-09-02 07:25:13,202 [INFO] Running workload in testing mode
client 2023-09-02 07:25:13,202 [INFO] Synchronizing with the server and with time.google.com...
client 2023-09-02 07:25:13,229 [INFO] NTP:offset = 0.000 s, delay = 0.015 s 
client 2023-09-02 07:25:13,229 [INFO] Sending command to the server: 'time'
client 2023-09-02 07:25:13,231 [INFO] Got response: '1693664713.2320156'
client 2023-09-02 07:25:13,231 [INFO] The time difference between the client and the server is within range -2.112 ms..-0.241 ms
client 2023-09-02 07:25:13,231 [INFO] Sending command to the server: 'session,2023-09-02_14-19-27,start,testing'
client 2023-09-02 07:25:26,251 [INFO] Got response: 'OK'
client 2023-09-02 07:25:26,251 [INFO] Sending command to the server: 'time'
client 2023-09-02 07:25:26,253 [INFO] Got response: '1693664726.2535026'
client 2023-09-02 07:25:26,253 [INFO] The time difference between the client and the server is within range -1.673 ms..-0.072 ms
client 2023-09-02 07:25:26,253 [INFO] Running the workload 'CM_MLPERF_RUN_COUNT=$(cat ${CM_RUN_DIR}/count.txt); echo ${CM_MLPERF_RUN_COUNT}; CM_MLPERF_RUN_COUNT=$((CM_MLPERF_RUN_COUNT+1)); echo ${CM_MLPERF_RUN_COUNT} > ${CM_RUN_DIR}/count.txt && if [ ${CM_MLPERF_RUN_COUNT} -eq "1" ]; then export CM_MLPERF_USER_CONF=${CM_MLPERF_RANGING_USER_CONF}; else export CM_MLPERF_USER_CONF=${CM_MLPERF_TESTING_USER_CONF}; fi && make run_harness RUN_ARGS=" --benchmarks=retinanet --scenarios=multistream --test_mode=PerformanceOnly --offline_expected_qps=620 --single_stream_expected_latency_ns=2000000 --multi_stream_expected_latency_ns=14000000 --user_conf_path=${CM_MLPERF_USER_CONF} --mlperf_conf_path=/home/cmuser/CM/repos/local/cache/e08d8d07b7714054/inference/mlperf.conf --gpu_batch_size=2 --no_audit_verify "'
client 2023-09-02 07:35:32,873 [INFO] Sending command to the server: 'time'
client 2023-09-02 07:35:32,903 [INFO] Got response: '1693665332.9024734'
client 2023-09-02 07:35:32,903 [INFO] The time difference between the client and the server is within range -28.844 ms..0.940 ms
client 2023-09-02 07:35:32,903 [INFO] Sending command to the server: 'session,2023-09-02_14-19-27,stop,testing'
client 2023-09-02 07:35:43,309 [INFO] Got response: 'OK'
client 2023-09-02 07:35:43,309 [INFO] Sending command to the server: 'time'
client 2023-09-02 07:35:43,310 [INFO] Got response: '1693665343.3105035'
client 2023-09-02 07:35:43,310 [INFO] The time difference between the client and the server is within range -0.536 ms..0.387 ms
client 2023-09-02 07:35:43,311 [INFO] Copying loadgen logs from '/home/cmuser/CM/repos/mlcommons@ck/cm-mlops/script/run-all-mlperf-models/valid_results/cecdad8c31f6-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream/performance/run_1' to '/home/cmuser/CM/repos/mlcommons@ck/cm-mlops/script/run-all-mlperf-models/valid_results/cecdad8c31f6-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream/performance/tmp_power/run_1'
client 2023-09-02 07:35:43,311 [INFO] Done runs
